#!/usr/bin/env python3

import cv2
import numpy as np
import os
import sys
from subprocess import check_output
from typing import List, Optional, Tuple, Union, cast

import gtsam
from detectron2 import config as d2c
from detectron2 import data as d2d
from detectron2 import engine as d2e
from detectron2 import model_zoo as d2mz
from detectron2.utils import visualizer as d2v

import quadricslam as q


class TumRgbd(q.DataSource):

    data_list_type = List[List[Union[float, str]]]

    def __init__(self, path: str) -> None:
        # Validate path exists
        self.path = path
        if not os.path.isdir(self.path):
            raise ValueError("Path '%s' does not exist." % self.path)

        # Derive synced dataset (aligning on depth as it always has the least
        # data)
        d = self._file_list('depth')
        self.data = {
            **{
                'depth': d
            },
            **{
                t: TumRgbd._synced_list(self._file_list(t), d) for t in [
                    'rgb', 'accelerometer', 'groundtruth'
                ]
            }
        }
        self.data_length = len(self.data['depth'])
        self.restart()

    def _file_list(self, type: str) -> data_list_type:
        fn = os.path.join(self.path, '%s.txt' % type)
        if not os.path.exists(fn):
            raise ValueError("File '%s' does not exist." % fn)
        return [[
            float(x) if i == 0 else x.decode('utf-8')
            for i, x in enumerate(l.split(b' '))
        ]
                for l in check_output("cat %s | grep -v '^#'" %
                                      fn, shell=True).strip().split(b'\n')]

    @staticmethod
    def _synced_list(candidates: data_list_type,
                     reference: data_list_type) -> data_list_type:
        ts_c = np.asarray([c[0] for c in candidates])
        ts_r = np.asarray([r[0] for r in reference])
        return [
            candidates[i] if i == 0 or
            np.abs(np.asarray([candidates[i][0], candidates[i - 1][0]
                              ])).argmin() == 0 else candidates[i - 1]
            for i in np.searchsorted(ts_c, ts_r)
        ]

    def done(self) -> bool:
        return self.data_i == self.data_length

    def next(
        self
    ) -> Tuple[Optional[gtsam.Pose3], np.ndarray, Optional[np.ndarray]]:
        i = self.data_i
        self.data_i += 1
        return None, cv2.imread(
            os.path.join(self.path, cast(str, self.data['rgb'][i][1]))), None

    def restart(self) -> None:
        self.data_i = 0


class FasterRcnn(q.Detector):

    def __init__(
            self,
            zoo_model: str = 'COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml',
            detection_thresh: float = 0.5) -> None:
        c = d2c.get_cfg()
        c.merge_from_file(d2mz.get_config_file(zoo_model))
        c.MODEL.ROI_HEADS.SCORE_THRESH_TEST = detection_thresh
        c.MODEL.WEIGHTS = d2mz.get_checkpoint_url(zoo_model)
        self.predictor = d2e.DefaultPredictor(c)

    def detect(self, rgb: np.ndarray) -> None:
        return self.predictor(rgb)


def _vis(rgb, detections, cfg):
    v = d2v.Visualizer(rgb[:, :, ::-1], d2d.MetadataCatalog.get(cfg))
    out = v.draw_instance_predictions(detections["instances"].to("cpu"))
    cv2.imshow('vis', out.get_image()[:, :, ::-1])


if __name__ == '__main__':
    ds = TumRgbd(sys.argv[1])
    de = FasterRcnn()
    while not ds.done():
        odom, rgb, depth = ds.next()
        detections = de.detect(rgb)
        _vis(rgb, detections, de.predictor.cfg.DATASETS.TRAIN[0])
        cv2.waitKey(100)
